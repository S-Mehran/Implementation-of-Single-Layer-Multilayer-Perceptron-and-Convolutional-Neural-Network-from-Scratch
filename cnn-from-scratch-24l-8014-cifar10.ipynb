{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":283795,"datasetId":118250,"databundleVersionId":296256}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\nimport pandas as pd\nimport random\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix\nimport time\nimport os\nfrom scipy.signal import correlate2d\nimport cv2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T20:38:18.279378Z","iopub.execute_input":"2025-03-05T20:38:18.279681Z","iopub.status.idle":"2025-03-05T20:38:18.708197Z","shell.execute_reply.started":"2025-03-05T20:38:18.279654Z","shell.execute_reply":"2025-03-05T20:38:18.707144Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class CNN:\n    def __init__(self, input_size=(28, 28), num_filters=8, filter_size=3, pool_size=2, num_classes=10, learning_rate=0.01):\n        self.input_size = input_size\n        self.num_filters = num_filters\n        self.filter_size = filter_size\n        self.pool_size = pool_size\n        self.num_classes = num_classes\n        self.lr = learning_rate\n\n        # Initialize filters and weights\n        self.filters = np.random.randn(num_filters, filter_size, filter_size) * 0.1\n        self.fc_weights = np.random.randn(num_filters * ((input_size[0] - filter_size + 1) // pool_size) * \n                                          ((input_size[1] - filter_size + 1) // pool_size), num_classes) * 0.1\n        self.fc_bias = np.zeros((1, num_classes))\n\n    def convolve2D(self, image, kernel):\n        return correlate2d(image, kernel, mode='valid')\n\n        # kernel_size = kernel.shape[0]\n        # output_size = (image.shape[0] - kernel_size + 1, image.shape[1] - kernel_size + 1)\n        # output = np.zeros(output_size)\n\n        # for i in range(output_size[0]):\n        #     for j in range(output_size[1]):\n        #         region = image[i:i + kernel_size, j:j + kernel_size]\n        #         output[i, j] = np.sum(region * kernel)\n\n        # return output\n\n    def max_pooling(self, feature_map, size):\n        h, w = feature_map.shape\n        output_size = (h // size, w // size)\n        output = np.zeros(output_size)\n        self.pool_cache = {}\n\n        for i in range(output_size[0]):\n            for j in range(output_size[1]):\n                region = feature_map[i * size:(i + 1) * size, j * size:(j + 1) * size]\n                max_val = np.max(region)\n                max_pos = np.unravel_index(np.argmax(region), region.shape)\n                output[i, j] = max_val\n                self.pool_cache[(i, j)] = (i * size + max_pos[0], j * size + max_pos[1])  # Store relative positions\n\n        return output\n\n    def sigmoid(self, x):\n        x = np.clip(x, -500, 500)  # Prevent overflow\n        return 1 / (1 + np.exp(-x))\n\n    def sigmoid_derivative(self, x):\n        return x * (1 - x)\n\n    def softmax(self, x):\n        exps = np.exp(x - np.max(x))\n        return exps / np.sum(exps, axis=1, keepdims=True)\n\n    def cross_entropy_loss(self, probs, label):\n        probs = np.clip(probs, 1e-10, 1)  # Prevent log(0)\n        return -np.log(probs[0, label])  # Corrected label indexing\n\n    def forward(self, image):\n        self.input_image = image\n        self.feature_maps = np.array([self.convolve2D(image, kernel) for kernel in self.filters])\n        self.sigmoid_maps = np.array([self.sigmoid(x) for x in self.feature_maps])\n        self.pooled_maps = np.array([self.max_pooling(fm, self.pool_size) for fm in self.sigmoid_maps])\n\n        self.flattened = self.pooled_maps.flatten().reshape(1, -1)\n        self.scores = np.dot(self.flattened, self.fc_weights) + self.fc_bias\n        self.probs = self.softmax(self.scores)\n\n        return self.probs\n\n    def backward(self, label):\n        d_scores = self.probs.copy()  # Don't modify self.probs\n        d_scores[0, label] -= 1  # Compute gradient of loss w.r.t. scores\n\n        d_fc_weights = np.dot(self.flattened.T, d_scores)\n        d_fc_bias = np.sum(d_scores, axis=0, keepdims=True)\n        d_flattened = np.dot(d_scores, self.fc_weights.T)\n\n        d_pooled = d_flattened.reshape(self.pooled_maps.shape)\n\n        # Backprop through pooling\n        d_sigmoid_maps = np.zeros_like(self.sigmoid_maps)\n        for i in range(self.num_filters):\n            for (py, px), (y, x) in self.pool_cache.items():\n                d_sigmoid_maps[i, y, x] = d_pooled[i, py, px]  # Use stored pooling indices\n\n        # Backprop through sigmoid\n        d_feature_maps = d_sigmoid_maps * self.sigmoid_derivative(self.sigmoid_maps)\n\n        # Backprop through convolution\n        d_filters = np.zeros_like(self.filters)\n        for i in range(self.num_filters):\n            for y in range(self.filter_size):\n                for x in range(self.filter_size):\n                    region = self.input_image[y:y + d_feature_maps.shape[1], x:x + d_feature_maps.shape[2]]\n                    d_filters[i, y, x] = np.sum(region * d_feature_maps[i])\n\n        # Gradient clipping to prevent instability\n        d_fc_weights = np.clip(d_fc_weights, -1, 1)\n        d_fc_bias = np.clip(d_fc_bias, -1, 1)\n        d_filters = np.clip(d_filters, -1, 1)\n\n        # Update weights\n        self.fc_weights -= self.lr * d_fc_weights\n        self.fc_bias -= self.lr * d_fc_bias\n        self.filters -= self.lr * d_filters\n\n\n    def predict(self, image):\n        \"\"\" Returns predicted class label \"\"\"\n        output = self.forward(image)\n        return np.argmax(output)\n\n    def train(self, dataset, labels, epochs=10, batch_size=32):\n        num_samples = dataset.shape[0]\n        history = {'loss': [], 'f1_score': [], 'training_time': []}\n        \n        for epoch in range(epochs):\n            start_time = time.time()\n            loss = 0\n            num_batches = num_samples//batch_size\n            all_preds = []\n            all_labels = []\n            \n            with tqdm(total=num_batches, desc=f\"Epoch {epoch + 1}/{epochs}\") as pbar:\n                for i in range(0, num_samples, batch_size):\n                    X_batch = dataset[i:i+batch_size]\n                    y_batch = labels[i:i+batch_size]\n                    batch_loss = 0\n            \n                    for image, label in zip(X_batch, y_batch):\n                        #image, label = dataset[i], labels[i]\n                        output = self.forward(image)\n                        batch_loss += self.cross_entropy_loss(output, label)\n                        self.backward(label)\n\n                        pred_label = np.argmax(output)\n                        all_preds.append(pred_label)\n                        all_labels.append(label)\n                    loss+= batch_loss/len(X_batch)\n                    pbar.update(1)\n\n            avg_loss = loss / len(dataset)\n            f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n            epoch_time = time.time() - start_time\n\n            history['loss'].append(avg_loss)\n            history['f1_score'].append(f1)\n            history['training_time'].append(epoch_time)\n\n            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}\")\n            print(\"f1 score: \", f1)\n        return history\n\n\n    def evaluate(self, dataset, labels):\n        preds = np.array([self.predict(image) for image in dataset])\n        labels = np.array(labels)\n        \n        accuracy = np.mean(preds == labels)\n        f1 = f1_score(labels, preds, average=\"weighted\")\n        conf_matrix = confusion_matrix(labels, preds)\n\n        print(f\"Accuracy: {accuracy * 100:.2f}%\")\n        print(f\"F1 Score: {f1:.4f}\")\n        print(f\"Confusion Matrix:\\n{conf_matrix}\")\n\n        return {\"accuracy\": accuracy, \"f1_score\": f1, \"confusion_matrix\": conf_matrix}\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:38:54.032732Z","iopub.execute_input":"2025-03-05T21:38:54.033012Z","iopub.status.idle":"2025-03-05T21:38:54.050773Z","shell.execute_reply.started":"2025-03-05T21:38:54.032990Z","shell.execute_reply":"2025-03-05T21:38:54.049717Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"\n# Load CIFAR-10 dataset\ntrain_path = \"/kaggle/input/cifar10-pngs-in-folders/cifar10/train\"\ntest_path = \"/kaggle/input/cifar10-pngs-in-folders/cifar10/test\"\n\ndef load_cifar10(dataset_path):\n    categories = os.listdir(dataset_path)\n    label_map = {category: idx for idx, category in enumerate(categories)}\n    \n    images, labels = [], []\n    for category in categories:\n        category_path = os.path.join(dataset_path, category)\n        for img_file in os.listdir(category_path):\n            img_path = os.path.join(category_path, img_file)\n            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n            img = cv2.resize(img, (32, 32)) / 255.0  # Normalize\n            images.append(img)\n            labels.append(label_map[category])\n    \n    return np.array(images), np.array(labels)\n\n# Load dataset\nX_train, y_train = load_cifar10(train_path)\nX_test, y_test = load_cifar10(test_path)\nX_train = X_train.reshape(X_train.shape[0], 32, 32)\nX_test = X_test.reshape(X_test.shape[0], 32, 32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:39:46.553823Z","iopub.execute_input":"2025-03-05T21:39:46.554215Z","iopub.status.idle":"2025-03-05T21:40:57.574196Z","shell.execute_reply.started":"2025-03-05T21:39:46.554185Z","shell.execute_reply":"2025-03-05T21:40:57.573390Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"\n# Paths to dataset\ntrain_path = \"/kaggle/input/cifar10-pngs-in-folders/cifar10/train\"\ntest_path = \"/kaggle/input/cifar10-pngs-in-folders/cifar10/test\"\n\ndef load_cifar10(dataset_path, num_samples=10000):\n    categories = os.listdir(dataset_path)\n    label_map = {category: idx for idx, category in enumerate(categories)}\n    \n    images, labels = [], []\n    \n    for category in categories:\n        category_path = os.path.join(dataset_path, category)\n        img_files = os.listdir(category_path)\n\n        # Ensure we don't sample more images than available\n        num_to_sample = min(num_samples // len(categories), len(img_files))\n        sampled_files = np.random.choice(img_files, size=num_to_sample, replace=False)\n\n        for img_file in sampled_files:\n            img_path = os.path.join(category_path, img_file)\n            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n            if img is None:\n                print(f\"Warning: Unable to read {img_path}\")\n                continue  # Skip unreadable images\n            \n            img = cv2.resize(img, (32, 32)) / 255.0  # Normalize\n            images.append(img)\n            labels.append(label_map[category])\n    \n    return np.array(images), np.array(labels)\n\n# Load dataset\nX_train, y_train = load_cifar10(train_path, num_samples=10000)\nX_test, y_test = load_cifar10(test_path, num_samples=10000)\n\n# Shuffle data\nindices = np.arange(X_train.shape[0])\nnp.random.shuffle(indices)\nX_train, y_train = X_train[indices], y_train[indices]\n\nindices = np.arange(X_test.shape[0])\nnp.random.shuffle(indices)\nX_test, y_test = X_test[indices], y_test[indices]\n\nprint(\"Train data shape:\", X_train.shape, y_train.shape)\nprint(\"Test data shape:\", X_test.shape, y_test.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T22:09:04.311795Z","iopub.execute_input":"2025-03-05T22:09:04.312059Z","iopub.status.idle":"2025-03-05T22:09:45.940951Z","shell.execute_reply.started":"2025-03-05T22:09:04.312039Z","shell.execute_reply":"2025-03-05T22:09:45.939959Z"}},"outputs":[{"name":"stdout","text":"Train data shape: (10000, 32, 32) (10000,)\nTest data shape: (10000, 32, 32) (10000,)\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"\n# CNN Class (same as provided, with input size updated)\ncnn = CNN(input_size=(32, 32), num_filters=8, filter_size=3, pool_size=2, num_classes=10, learning_rate=0.01)\n\n# Train the model\nhistory = cnn.train(X_train, y_train, epochs=10, batch_size=32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T22:10:35.430706Z","iopub.execute_input":"2025-03-05T22:10:35.431022Z","iopub.status.idle":"2025-03-05T22:37:21.617951Z","shell.execute_reply.started":"2025-03-05T22:10:35.430997Z","shell.execute_reply":"2025-03-05T22:37:21.617140Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/10: 313it [02:40,  1.95it/s]                         \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10, Loss: 0.0700\nf1 score:  0.2179732898236508\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10: 313it [02:40,  1.96it/s]                         \n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/10, Loss: 0.0660\nf1 score:  0.2537552259641321\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10: 313it [02:40,  1.95it/s]                         \n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/10, Loss: 0.0651\nf1 score:  0.26652397658945004\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10: 313it [02:40,  1.95it/s]                         \n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/10, Loss: 0.0643\nf1 score:  0.27742704206830815\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10: 313it [02:40,  1.95it/s]                         \n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/10, Loss: 0.0636\nf1 score:  0.2840992408021809\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10: 313it [02:40,  1.94it/s]                         \n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/10, Loss: 0.0630\nf1 score:  0.29247083148036\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10: 313it [02:40,  1.95it/s]                         \n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/10, Loss: 0.0625\nf1 score:  0.29761558552793005\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10: 313it [02:40,  1.95it/s]                         \n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/10, Loss: 0.0620\nf1 score:  0.30187695577416296\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10: 313it [02:40,  1.95it/s]                         \n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/10, Loss: 0.0613\nf1 score:  0.3096304773881331\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10: 313it [02:41,  1.94it/s]                         ","output_type":"stream"},{"name":"stdout","text":"Epoch 10/10, Loss: 0.0600\nf1 score:  0.3243521103946366\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"\n# Evaluate on test set\neval_results = cnn.evaluate(X_test, y_test)\nprint(\"Evaluation Results:\", eval_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T22:42:17.934918Z","iopub.execute_input":"2025-03-05T22:42:17.935197Z","iopub.status.idle":"2025-03-05T22:44:46.842216Z","shell.execute_reply.started":"2025-03-05T22:42:17.935171Z","shell.execute_reply":"2025-03-05T22:44:46.841290Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 30.74%\nF1 Score: 0.2783\nConfusion Matrix:\n[[417 103  81  33  66  82 110 101   1   6]\n [ 80 406  59  26  20 180  84 126   7  12]\n [ 72  60 467 173  51  40  26 108   2   1]\n [ 55  53 264 347  34  81  12 150   3   1]\n [216  72 187  66 212 105  60  82   0   0]\n [ 59 159  23  11  25 455 118 135   9   6]\n [126 114  33  21  20 213 291 166  11   5]\n [ 69  88  67  41  15 186  82 448   3   1]\n [ 87 135  49  27  15 371 106 197  12   1]\n [ 88 143  24  16  18 296 176 219   1  19]]\nEvaluation Results: {'accuracy': 0.3074, 'f1_score': 0.2782575822167615, 'confusion_matrix': array([[417, 103,  81,  33,  66,  82, 110, 101,   1,   6],\n       [ 80, 406,  59,  26,  20, 180,  84, 126,   7,  12],\n       [ 72,  60, 467, 173,  51,  40,  26, 108,   2,   1],\n       [ 55,  53, 264, 347,  34,  81,  12, 150,   3,   1],\n       [216,  72, 187,  66, 212, 105,  60,  82,   0,   0],\n       [ 59, 159,  23,  11,  25, 455, 118, 135,   9,   6],\n       [126, 114,  33,  21,  20, 213, 291, 166,  11,   5],\n       [ 69,  88,  67,  41,  15, 186,  82, 448,   3,   1],\n       [ 87, 135,  49,  27,  15, 371, 106, 197,  12,   1],\n       [ 88, 143,  24,  16,  18, 296, 176, 219,   1,  19]])}\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}