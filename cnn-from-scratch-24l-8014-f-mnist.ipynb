{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9243,"sourceType":"datasetVersion","datasetId":2243}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-05T16:29:07.273069Z","iopub.execute_input":"2025-03-05T16:29:07.273455Z","iopub.status.idle":"2025-03-05T16:29:07.708881Z","shell.execute_reply.started":"2025-03-05T16:29:07.273416Z","shell.execute_reply":"2025-03-05T16:29:07.707679Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/fashionmnist/t10k-labels-idx1-ubyte\n/kaggle/input/fashionmnist/t10k-images-idx3-ubyte\n/kaggle/input/fashionmnist/fashion-mnist_test.csv\n/kaggle/input/fashionmnist/fashion-mnist_train.csv\n/kaggle/input/fashionmnist/train-labels-idx1-ubyte\n/kaggle/input/fashionmnist/train-images-idx3-ubyte\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\nimport pandas as pd\nimport random\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix\nimport time\nimport os\nfrom scipy.signal import correlate2d\nfrom skimage.measure import block_reduce\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T16:29:07.709773Z","iopub.execute_input":"2025-03-05T16:29:07.710226Z","iopub.status.idle":"2025-03-05T16:29:08.658229Z","shell.execute_reply.started":"2025-03-05T16:29:07.710127Z","shell.execute_reply":"2025-03-05T16:29:08.657053Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"\n\nclass CNN:\n    def __init__(self, input_size=(28, 28), num_filters=8, filter_size=3, pool_size=2, num_classes=10, learning_rate=0.01):\n        self.input_size = input_size\n        self.num_filters = num_filters\n        self.filter_size = filter_size\n        self.pool_size = pool_size\n        self.num_classes = num_classes\n        self.lr = learning_rate\n\n        # Initialize filters and weights\n        self.filters = np.random.randn(num_filters, filter_size, filter_size) * 0.1\n        self.fc_weights = np.random.randn(num_filters * ((input_size[0] - filter_size + 1) // pool_size) * \n                                          ((input_size[1] - filter_size + 1) // pool_size), num_classes) * 0.1\n        self.fc_bias = np.zeros((1, num_classes))\n\n    def convolve2D(self, image, kernel):\n        return correlate2d(image, kernel, mode='valid')\n\n        # kernel_size = kernel.shape[0]\n        # output_size = (image.shape[0] - kernel_size + 1, image.shape[1] - kernel_size + 1)\n        # output = np.zeros(output_size)\n\n        # for i in range(output_size[0]):\n        #     for j in range(output_size[1]):\n        #         region = image[i:i + kernel_size, j:j + kernel_size]\n        #         output[i, j] = np.sum(region * kernel)\n\n        # return output\n\n    def max_pooling(self, feature_map, size):\n        # return block_reduce(feature_map, (size, size), np.max)\n        h, w = feature_map.shape\n        output_size = (h // size, w // size)\n        output = np.zeros(output_size)\n        self.pool_cache = {}\n\n        for i in range(output_size[0]):\n            for j in range(output_size[1]):\n                region = feature_map[i * size:(i + 1) * size, j * size:(j + 1) * size]\n                max_val = np.max(region)\n                max_pos = np.unravel_index(np.argmax(region), region.shape)\n                output[i, j] = max_val\n                self.pool_cache[(i, j)] = (i * size + max_pos[0], j * size + max_pos[1])  # Store relative positions\n\n        return output\n\n    def sigmoid(self, x):\n        x = np.clip(x, -500, 500)  # Prevent overflow\n        return 1 / (1 + np.exp(-x))\n\n    def sigmoid_derivative(self, x):\n        return x * (1 - x)\n\n    def softmax(self, x):\n        exps = np.exp(x - np.max(x))\n        return exps / np.sum(exps, axis=1, keepdims=True)\n\n    def cross_entropy_loss(self, probs, label):\n        probs = np.clip(probs, 1e-10, 1)  # Prevent log(0)\n        return -np.log(probs[0, label])  # Corrected label indexing\n\n    def forward(self, image):\n        self.input_image = image\n        self.feature_maps = np.array([self.convolve2D(image, kernel) for kernel in self.filters])\n        self.sigmoid_maps = np.array([self.sigmoid(x) for x in self.feature_maps])\n        self.pooled_maps = np.array([self.max_pooling(fm, self.pool_size) for fm in self.sigmoid_maps])\n\n        self.flattened = self.pooled_maps.flatten().reshape(1, -1)\n        self.scores = np.dot(self.flattened, self.fc_weights) + self.fc_bias\n        self.probs = self.softmax(self.scores)\n\n        return self.probs\n\n    def backward(self, label):\n        d_scores = self.probs.copy()  # Don't modify self.probs\n        d_scores[0, label] -= 1  # Compute gradient of loss w.r.t. scores\n\n        d_fc_weights = np.dot(self.flattened.T, d_scores)\n        d_fc_bias = np.sum(d_scores, axis=0, keepdims=True)\n        d_flattened = np.dot(d_scores, self.fc_weights.T)\n\n        d_pooled = d_flattened.reshape(self.pooled_maps.shape)\n\n        # Backprop through pooling\n        d_sigmoid_maps = np.zeros_like(self.sigmoid_maps)\n        for i in range(self.num_filters):\n            for (py, px), (y, x) in self.pool_cache.items():\n                d_sigmoid_maps[i, y, x] = d_pooled[i, py, px]  # Use stored pooling indices\n\n        # Backprop through sigmoid\n        d_feature_maps = d_sigmoid_maps * self.sigmoid_derivative(self.sigmoid_maps)\n\n        # Backprop through convolution\n        d_filters = np.zeros_like(self.filters)\n        for i in range(self.num_filters):\n            for y in range(self.filter_size):\n                for x in range(self.filter_size):\n                    region = self.input_image[y:y + d_feature_maps.shape[1], x:x + d_feature_maps.shape[2]]\n                    d_filters[i, y, x] = np.sum(region * d_feature_maps[i])\n\n        # Gradient clipping to prevent instability\n        d_fc_weights = np.clip(d_fc_weights, -1, 1)\n        d_fc_bias = np.clip(d_fc_bias, -1, 1)\n        d_filters = np.clip(d_filters, -1, 1)\n\n        # Update weights\n        self.fc_weights -= self.lr * d_fc_weights\n        self.fc_bias -= self.lr * d_fc_bias\n        self.filters -= self.lr * d_filters\n\n\n    def predict(self, image):\n        \"\"\" Returns predicted class label \"\"\"\n        output = self.forward(image)\n        return np.argmax(output)\n\n    def train(self, dataset, labels, epochs=10, batch_size=32):\n        num_samples = dataset.shape[0]\n        history = {'loss': [], 'f1_score': [], 'training_time': []}\n        \n        for epoch in range(epochs):\n            start_time = time.time()\n            loss = 0\n            num_batches = num_samples//batch_size\n            all_preds = []\n            all_labels = []\n            \n            with tqdm(total=num_batches, desc=f\"Epoch {epoch + 1}/{epochs}\") as pbar:\n                for i in range(0, num_samples, batch_size):\n                    X_batch = dataset[i:i+batch_size]\n                    y_batch = labels[i:i+batch_size]\n                    batch_loss = 0\n            \n                    for image, label in zip(X_batch, y_batch):\n                        #image, label = dataset[i], labels[i]\n                        output = self.forward(image)\n                        batch_loss += self.cross_entropy_loss(output, label)\n                        self.backward(label)\n\n                        pred_label = np.argmax(output)\n                        all_preds.append(pred_label)\n                        all_labels.append(label)\n                    loss+= batch_loss/len(X_batch)\n                    pbar.update(1)\n\n            avg_loss = loss / len(dataset)\n            f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n            epoch_time = time.time() - start_time\n\n            history['loss'].append(avg_loss)\n            history['f1_score'].append(f1)\n            history['training_time'].append(epoch_time)\n\n            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}\")\n        return history\n\n\n    def evaluate(self, dataset, labels):\n        preds = np.array([self.predict(image) for image in dataset])\n        labels = np.array(labels)\n        \n        accuracy = np.mean(preds == labels)\n        f1 = f1_score(labels, preds, average=\"weighted\")\n        conf_matrix = confusion_matrix(labels, preds)\n\n        print(f\"Accuracy: {accuracy * 100:.2f}%\")\n        print(f\"F1 Score: {f1:.4f}\")\n        print(f\"Confusion Matrix:\\n{conf_matrix}\")\n\n        return {\"accuracy\": accuracy, \"f1_score\": f1, \"confusion_matrix\": conf_matrix}\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T16:51:14.935789Z","iopub.execute_input":"2025-03-05T16:51:14.936239Z","iopub.status.idle":"2025-03-05T16:51:14.962490Z","shell.execute_reply.started":"2025-03-05T16:51:14.936205Z","shell.execute_reply":"2025-03-05T16:51:14.961107Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Load MNIST dataset (CSV format)\ntrain_data = pd.read_csv('/kaggle/input/fashionmnist/fashion-mnist_train.csv')\ntest_data = pd.read_csv('/kaggle/input/fashionmnist/fashion-mnist_test.csv')\ntrain_data['label'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T16:29:08.767670Z","iopub.execute_input":"2025-03-05T16:29:08.768025Z","iopub.status.idle":"2025-03-05T16:29:15.871220Z","shell.execute_reply.started":"2025-03-05T16:29:08.767975Z","shell.execute_reply":"2025-03-05T16:29:15.869729Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"label\n2    6000\n9    6000\n6    6000\n0    6000\n3    6000\n4    6000\n5    6000\n8    6000\n7    6000\n1    6000\nName: count, dtype: int64"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"\n# Split features and labels\nX_train = train_data.iloc[0:10000, 1:].values  # Pixels\ny_train = train_data.iloc[0:10000, 0].values   # Labels\n\nX_test = test_data.iloc[0:10000, 1:].values\ny_test = test_data.iloc[0:10000, 0].values\n\n# Normalize pixel values (0 to 1)\nX_train = X_train / 255.0\nX_test = X_test / 255.0\n\n# Reshape to (28, 28) for CNN input\nX_train = X_train.reshape(-1, 28, 28)\nX_test = X_test.reshape(-1, 28, 28)\n\n# Define number of classes\nnum_classes = 10\n\n# One-hot encode labels\ndef one_hot_encode(y, num_classes):\n    encoded = np.zeros((len(y), num_classes))\n    encoded[np.arange(len(y)), y] = 1\n    return encoded\n\ny_train_one_hot = one_hot_encode(y_train, num_classes)\ny_test_one_hot = one_hot_encode(y_test, num_classes)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T17:10:55.799801Z","iopub.execute_input":"2025-03-05T17:10:55.800244Z","iopub.status.idle":"2025-03-05T17:10:55.861899Z","shell.execute_reply.started":"2025-03-05T17:10:55.800212Z","shell.execute_reply":"2025-03-05T17:10:55.860991Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"\ncnn = CNN(input_size=(28, 28), num_filters=8, filter_size=3, pool_size=2, num_classes=10, learning_rate=0.01)\n\n# Train CNN on MNIST\nhistory = cnn.train(X_train, y_train, epochs=10)  # Using only 5000 samples for faster training\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T17:11:05.003414Z","iopub.execute_input":"2025-03-05T17:11:05.003875Z","iopub.status.idle":"2025-03-05T17:41:45.126625Z","shell.execute_reply.started":"2025-03-05T17:11:05.003830Z","shell.execute_reply":"2025-03-05T17:41:45.125440Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/10: 313it [03:05,  1.68it/s]                         \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10, Loss: 0.0289\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10: 313it [03:05,  1.69it/s]                         \n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/10, Loss: 0.0197\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10: 313it [03:04,  1.70it/s]                         \n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/10, Loss: 0.0180\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10: 313it [03:04,  1.70it/s]                         \n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/10, Loss: 0.0169\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10: 313it [03:01,  1.72it/s]                         \n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/10, Loss: 0.0160\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10: 313it [03:03,  1.71it/s]                         \n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/10, Loss: 0.0153\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10: 313it [03:03,  1.70it/s]                         \n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/10, Loss: 0.0147\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10: 313it [03:03,  1.71it/s]                         \n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/10, Loss: 0.0142\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10: 313it [03:03,  1.71it/s]                         \n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/10, Loss: 0.0138\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10: 313it [03:05,  1.69it/s]                         ","output_type":"stream"},{"name":"stdout","text":"Epoch 10/10, Loss: 0.0134\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"performance = cnn.evaluate(X_test, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T17:06:48.354392Z","iopub.execute_input":"2025-03-05T17:06:48.354651Z","iopub.status.idle":"2025-03-05T17:08:12.226928Z","shell.execute_reply.started":"2025-03-05T17:06:48.354629Z","shell.execute_reply":"2025-03-05T17:08:12.225770Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 81.78%\nF1 Score: 0.8184\nConfusion Matrix:\n[[366   1   5  46   0   1  62   0  21   0]\n [  0 457   0  23   0   0   9   0   1   0]\n [  3   0 302   9  55   2 110   0   9   0]\n [  3   2   1 468   3   0  27   0   3   0]\n [  0   3  39  43 324   0  96   0   1   0]\n [  0   0   0   0   0 428   0  40   7  15]\n [ 63   1  26  39  17   2 354   1  16   0]\n [  0   0   0   0   0  12   0 450   1   8]\n [  0   1   0   1   1   0   8   5 492   0]\n [  0   0   0   0   0   8   0  61   0 448]]\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}